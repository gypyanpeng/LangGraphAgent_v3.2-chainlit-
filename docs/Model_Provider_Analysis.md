# LangChain æ¨¡å‹ä¾›åº”å•†åº“åˆ†ææŠ¥å‘Š

## ğŸ“‹ æ‰§è¡Œæ‘˜è¦

æœ¬æŠ¥å‘Šæ·±å…¥åˆ†æäº† LangChain å¯¹ä¸åŒæ¨¡å‹ä¾›åº”å•†çš„æ”¯æŒç­–ç•¥ï¼Œç‰¹åˆ«å…³æ³¨æˆ‘ä»¬é¡¹ç›®ä¸­å¯èƒ½ä½¿ç”¨çš„ DeepSeekã€Qwen3ã€Ollama/VLLM ç­‰æ¨¡å‹çš„æœ€ä½³é›†æˆæ–¹æ¡ˆã€‚ç ”ç©¶å‘ç°ï¼ŒLangChain é‡‡ç”¨äº†åˆ†å±‚æ¶æ„è®¾è®¡ï¼Œé€šè¿‡ç»Ÿä¸€çš„æ¶ˆæ¯æ ¼å¼å’Œä¸“é—¨çš„ provider åŒ…æ¥æ”¯æŒä¸åŒä¾›åº”å•†ï¼Œè¿™ä¸ºæˆ‘ä»¬çš„å¤šæ¨¡å‹é…ç½®æä¾›äº†æ ‡å‡†åŒ–çš„è§£å†³æ–¹æ¡ˆã€‚

## ğŸ—ï¸ LangChain æ¶æ„åˆ†æ

### åˆ†å±‚æ¶æ„è®¾è®¡

```mermaid
graph TB
    A[åº”ç”¨å±‚] --> B[LangChain ç»Ÿä¸€æ¥å£]
    B --> C[langchain-core æ ¸å¿ƒæŠ½è±¡]
    C --> D[Provider ä¸“ç”¨åŒ…]
    D --> E[OpenAI API]
    D --> F[Anthropic API]
    D --> G[Ollama API]
    D --> H[å…¶ä»–ä¾›åº”å•† API]
    
    style C fill:#e1f5fe
    style D fill:#f3e5f5
```

### æ ¸å¿ƒç»„ä»¶

#### 1. langchain-core (æ ¸å¿ƒæŠ½è±¡å±‚)
- **èŒè´£**: å®šä¹‰ç»Ÿä¸€çš„æ¥å£å’Œæ¶ˆæ¯æ ¼å¼
- **å…³é”®ç±»**: BaseMessage, HumanMessage, AIMessage, SystemMessage, ToolMessage
- **è®¾è®¡ç†å¿µ**: "å®šä¹‰ LEGO ç§¯æœ¨çš„å½¢çŠ¶ï¼Œç¡®ä¿æ‰€æœ‰ç»„ä»¶å®Œç¾é…åˆ"

#### 2. Provider ä¸“ç”¨åŒ… (langchain-{provider})
- **å‘½åè§„èŒƒ**: `langchain-{provider}` (å¦‚ langchain-openai)
- **èŒè´£**: å°†ç»Ÿä¸€æ¥å£è½¬æ¢ä¸ºç‰¹å®šä¾›åº”å•†çš„ API è°ƒç”¨
- **ä¼˜åŠ¿**: ç‹¬ç«‹ç‰ˆæœ¬ç®¡ç†ã€ä¾èµ–éš”ç¦»ã€ä¸“é—¨ä¼˜åŒ–

#### 3. langchain-community (ç¤¾åŒºåŒ…)
- **èŒè´£**: åŒ…å«è¾ƒå°æˆ–å®éªŒæ€§çš„é›†æˆ
- **é€‚ç”¨åœºæ™¯**: æ–°å…´ä¾›åº”å•†ã€å®éªŒæ€§åŠŸèƒ½

## ğŸ” ä¸»è¦ä¾›åº”å•†åŒ…åˆ†æ

### å®˜æ–¹ Provider åŒ…

| ä¾›åº”å•† | åŒ…å | çŠ¶æ€ | æ”¯æŒæ¨¡å‹ |
|--------|------|------|----------|
| OpenAI | langchain-openai | âœ… å®˜æ–¹ç»´æŠ¤ | GPT-4, GPT-3.5, Embeddings |
| Anthropic | langchain-anthropic | âœ… å®˜æ–¹ç»´æŠ¤ | Claude 3, Claude 2 |
| Google | langchain-google-genai | âœ… å®˜æ–¹ç»´æŠ¤ | Gemini, PaLM |
| Google Vertex | langchain-google-vertexai | âœ… å®˜æ–¹ç»´æŠ¤ | Vertex AI æ¨¡å‹ |
| Ollama | langchain-ollama | âœ… å®˜æ–¹ç»´æŠ¤ | æœ¬åœ°éƒ¨ç½²æ¨¡å‹ |
| Cohere | langchain-cohere | âœ… å®˜æ–¹ç»´æŠ¤ | Command, Embed |
| Mistral | langchain-mistralai | âœ… å®˜æ–¹ç»´æŠ¤ | Mistral ç³»åˆ— |

### æˆ‘ä»¬é¡¹ç›®ç›¸å…³çš„ä¾›åº”å•†

#### 1. DeepSeek
```python
# ä¸“ç”¨åŒ…æ”¯æŒ
from langchain_deepseek import ChatDeepSeek

# ä½¿ç”¨æ–¹å¼
llm = ChatDeepSeek(
    model="deepseek-chat",
    api_key="your-api-key"
)
```

**çŠ¶æ€**: âœ… æœ‰ä¸“é—¨çš„ `langchain-deepseek` åŒ…
**å»ºè®®**: ä½¿ç”¨å®˜æ–¹åŒ…ï¼Œè·å¾—æœ€ä½³æ”¯æŒå’Œæ€§èƒ½

#### 2. Qwen3 (é€šä¹‰åƒé—®)
```python
# æ–¹æ¡ˆ1: é€šè¿‡ Ollama (æ¨è)
from langchain_ollama import ChatOllama

llm = ChatOllama(model="qwen2.5:latest")

# æ–¹æ¡ˆ2: é€šè¿‡ DashScope (é˜¿é‡Œäº‘)
from langchain_community.llms import Tongyi

llm = Tongyi(model_name="qwen-max")
```

**çŠ¶æ€**: ğŸ”„ å¤šç§é›†æˆæ–¹æ¡ˆ
**å»ºè®®**: æœ¬åœ°éƒ¨ç½²ä½¿ç”¨ Ollamaï¼Œäº‘ç«¯ä½¿ç”¨ DashScope

#### 3. Ollama/VLLM
```python
# Ollama å®˜æ–¹æ”¯æŒ
from langchain_ollama import ChatOllama, OllamaEmbeddings

# Chat æ¨¡å‹
chat = ChatOllama(model="llama3.1:8b")

# Embedding æ¨¡å‹
embeddings = OllamaEmbeddings(model="nomic-embed-text")
```

**çŠ¶æ€**: âœ… æœ‰ä¸“é—¨çš„ `langchain-ollama` åŒ…
**å»ºè®®**: ä½¿ç”¨å®˜æ–¹åŒ…ï¼Œæ”¯æŒå®Œæ•´çš„ Ollama ç”Ÿæ€

## ğŸ’¬ æ¶ˆæ¯æ ¼å¼ç»Ÿä¸€æ€§åˆ†æ

### ç»Ÿä¸€æ¶ˆæ¯æ ¼å¼

```mermaid
graph LR
    A[ç”¨æˆ·è¾“å…¥] --> B[HumanMessage]
    B --> C[LangChain ç»Ÿä¸€æ ¼å¼]
    C --> D[Provider é€‚é…å™¨]
    D --> E[OpenAI æ ¼å¼]
    D --> F[Anthropic æ ¼å¼]
    D --> G[Ollama æ ¼å¼]
    
    style C fill:#e8f5e8
    style D fill:#fff3e0
```

### æ¶ˆæ¯ç±»å‹å¯¹ç…§

| LangChain ç±»å‹ | OpenAI æ ¼å¼ | Anthropic æ ¼å¼ | è¯´æ˜ |
|----------------|-------------|----------------|------|
| HumanMessage | {"role": "user", "content": "..."} | {"role": "user", "content": "..."} | ç”¨æˆ·æ¶ˆæ¯ |
| AIMessage | {"role": "assistant", "content": "..."} | {"role": "assistant", "content": "..."} | AI å›å¤ |
| SystemMessage | {"role": "system", "content": "..."} | {"role": "system", "content": "..."} | ç³»ç»Ÿæç¤º |
| ToolMessage | {"role": "tool", "content": "..."} | {"role": "user", "content": "..."} | å·¥å…·ç»“æœ |

### æ ¼å¼è½¬æ¢æœºåˆ¶

```python
# LangChain è‡ªåŠ¨å¤„ç†æ ¼å¼è½¬æ¢
from langchain_core.messages import HumanMessage, AIMessage

# ç»Ÿä¸€çš„æ¶ˆæ¯åˆ›å»º
messages = [
    HumanMessage(content="Hello"),
    AIMessage(content="Hi there!")
]

# ä¸åŒ provider è‡ªåŠ¨è½¬æ¢ä¸ºå¯¹åº”æ ¼å¼
openai_llm.invoke(messages)    # è½¬æ¢ä¸º OpenAI æ ¼å¼
anthropic_llm.invoke(messages) # è½¬æ¢ä¸º Anthropic æ ¼å¼
ollama_llm.invoke(messages)    # è½¬æ¢ä¸º Ollama æ ¼å¼
```

## ğŸ¯ å¯¹æˆ‘ä»¬é¡¹ç›®çš„å»ºè®®

### å½“å‰æ¶æ„è¯„ä¼°

æŸ¥çœ‹æˆ‘ä»¬çš„ `llm_config.json`:
```json
{
  "activeProvider": "modelscope",
  "configs": {
    "modelscope": {...},
    "ollama": {...}
  }
}
```

### æ¨èçš„æ”¹è¿›æ–¹æ¡ˆ

#### 1. ä¾èµ–ç®¡ç†ä¼˜åŒ–

**å½“å‰æ–¹å¼** (å¯èƒ½å­˜åœ¨çš„é—®é¢˜):
```python
# å¯èƒ½ä½¿ç”¨é€šç”¨åŒ…
from langchain_community.llms import SomeGenericLLM
```

**æ¨èæ–¹å¼** (ä½¿ç”¨ä¸“é—¨åŒ…):
```python
# å®‰è£…ä¸“é—¨çš„ provider åŒ…
# pip install langchain-deepseek langchain-ollama

from langchain_deepseek import ChatDeepSeek
from langchain_ollama import ChatOllama
```

#### 2. é…ç½®ç»“æ„è°ƒæ•´

**æ¨èçš„æ–°é…ç½®ç»“æ„**:
```json
{
  "activeProvider": "deepseek",
  "providers": {
    "deepseek": {
      "package": "langchain-deepseek",
      "class": "ChatDeepSeek",
      "config": {
        "model": "deepseek-chat",
        "api_key": "${DEEPSEEK_API_KEY}"
      }
    },
    "qwen3": {
      "package": "langchain-ollama",
      "class": "ChatOllama", 
      "config": {
        "model": "qwen2.5:latest",
        "base_url": "http://localhost:11434"
      }
    },
    "ollama": {
      "package": "langchain-ollama",
      "class": "ChatOllama",
      "config": {
        "model": "llama3.1:8b"
      }
    }
  }
}
```

#### 3. ä»£ç é‡æ„å»ºè®®

**å½“å‰çš„ llm_loader.py å¯èƒ½éœ€è¦è°ƒæ•´**:
```python
def load_llm_from_config(config_file: str):
    # å½“å‰å¯èƒ½ä½¿ç”¨é€šç”¨åŠ è½½æ–¹å¼
    # å»ºè®®æ”¹ä¸ºåŸºäº provider åŒ…çš„åŠ è½½
    
    config = load_config(config_file)
    provider_config = config["providers"][config["activeProvider"]]
    
    # åŠ¨æ€å¯¼å…¥ä¸“é—¨çš„åŒ…
    package_name = provider_config["package"]
    class_name = provider_config["class"]
    
    module = importlib.import_module(package_name)
    llm_class = getattr(module, class_name)
    
    return llm_class(**provider_config["config"])
```

### å®æ–½ä¼˜å…ˆçº§

#### Phase 1: ç«‹å³æ”¹è¿› (æœ¬å‘¨)
1. **è¯„ä¼°å½“å‰ä¾èµ–**: æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†æœ€ä½³çš„ provider åŒ…
2. **å®‰è£…ä¸“é—¨åŒ…**: 
   ```bash
   pip install langchain-deepseek langchain-ollama
   ```
3. **æµ‹è¯•å…¼å®¹æ€§**: ç¡®ä¿ç°æœ‰åŠŸèƒ½æ­£å¸¸å·¥ä½œ

#### Phase 2: æ¶æ„ä¼˜åŒ– (ä¸‹å‘¨)
1. **é‡æ„é…ç½®ç»“æ„**: é‡‡ç”¨æ–°çš„ provider é…ç½®æ ¼å¼
2. **æ›´æ–° llm_loader**: æ”¯æŒåŠ¨æ€ provider åŒ…åŠ è½½
3. **æ·»åŠ é”™è¯¯å¤„ç†**: å¤„ç†åŒ…ç¼ºå¤±ã€é…ç½®é”™è¯¯ç­‰æƒ…å†µ

#### Phase 3: åŠŸèƒ½å¢å¼º (åç»­)
1. **æ”¯æŒæ›´å¤šæ¨¡å‹**: æ·»åŠ å…¶ä»– provider åŒ…æ”¯æŒ
2. **æ€§èƒ½ä¼˜åŒ–**: åˆ©ç”¨ä¸“é—¨åŒ…çš„ä¼˜åŒ–ç‰¹æ€§
3. **ç›‘æ§å’Œæ—¥å¿—**: æ·»åŠ  provider ç‰¹å®šçš„ç›‘æ§

## ğŸ“Š æ€§èƒ½å’Œå…¼å®¹æ€§å¯¹æ¯”

### Provider åŒ… vs Community åŒ…

| ç‰¹æ€§ | Provider ä¸“ç”¨åŒ… | Community åŒ… |
|------|----------------|---------------|
| æ€§èƒ½ä¼˜åŒ– | âœ… ä¸“é—¨ä¼˜åŒ– | âš ï¸ é€šç”¨å®ç° |
| åŠŸèƒ½å®Œæ•´æ€§ | âœ… å®Œæ•´æ”¯æŒ | âš ï¸ åŸºç¡€åŠŸèƒ½ |
| æ›´æ–°é¢‘ç‡ | âœ… åŠæ—¶æ›´æ–° | âš ï¸ ç›¸å¯¹æ»å |
| ä¾èµ–ç®¡ç† | âœ… ç‹¬ç«‹ç®¡ç† | âŒ ä¾èµ–å†²çªé£é™© |
| å®˜æ–¹æ”¯æŒ | âœ… å®˜æ–¹ç»´æŠ¤ | âš ï¸ ç¤¾åŒºç»´æŠ¤ |

### æ¶ˆæ¯æ ¼å¼å…¼å®¹æ€§

æ‰€æœ‰ LangChain é›†æˆéƒ½æ”¯æŒç»Ÿä¸€çš„æ¶ˆæ¯æ ¼å¼ï¼Œæ— éœ€æ‹…å¿ƒæ ¼å¼å·®å¼‚ï¼š

```python
# ç»Ÿä¸€çš„æ¶ˆæ¯å¤„ç†
messages = [
    SystemMessage(content="You are a helpful assistant"),
    HumanMessage(content="Hello"),
    AIMessage(content="Hi! How can I help?"),
    ToolMessage(content="Tool result", tool_call_id="123")
]

# æ‰€æœ‰ provider éƒ½æ”¯æŒç›¸åŒçš„æ¶ˆæ¯æ ¼å¼
deepseek_response = deepseek_llm.invoke(messages)
qwen_response = qwen_llm.invoke(messages)
ollama_response = ollama_llm.invoke(messages)
```

## ğŸ”š ç»“è®ºå’Œå»ºè®®

### å…³é”®å‘ç°

1. **LangChain è®¾è®¡ä¼˜ç§€**: ç»Ÿä¸€æ¥å£ + ä¸“é—¨åŒ…çš„æ¶æ„å¾ˆå¥½åœ°è§£å†³äº†å¤šä¾›åº”å•†æ”¯æŒé—®é¢˜
2. **æ¶ˆæ¯æ ¼å¼ç»Ÿä¸€**: æ— éœ€æ‹…å¿ƒä¸åŒä¾›åº”å•†çš„æ¶ˆæ¯æ ¼å¼å·®å¼‚
3. **æˆ‘ä»¬é¡¹ç›®å¯ä»¥ä¼˜åŒ–**: é€šè¿‡ä½¿ç”¨ä¸“é—¨çš„ provider åŒ…è·å¾—æ›´å¥½çš„æ€§èƒ½å’Œæ”¯æŒ

### ç«‹å³è¡ŒåŠ¨å»ºè®®

1. **è¯„ä¼°å½“å‰å®ç°**: æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†æœ€ä½³çš„ provider åŒ…
2. **å®‰è£…ä¸“é—¨åŒ…**: `pip install langchain-deepseek langchain-ollama`
3. **æµ‹è¯•å…¼å®¹æ€§**: ç¡®ä¿åˆ‡æ¢ä¸ä¼šç ´åç°æœ‰åŠŸèƒ½

### é•¿æœŸè§„åˆ’

1. **é‡æ„é…ç½®ç³»ç»Ÿ**: é‡‡ç”¨åŸºäº provider åŒ…çš„é…ç½®ç»“æ„
2. **ä¼˜åŒ–åŠ è½½æœºåˆ¶**: å®ç°åŠ¨æ€ provider åŒ…åŠ è½½
3. **å¢å¼ºé”™è¯¯å¤„ç†**: æä¾›æ›´å¥½çš„é”™è¯¯è¯Šæ–­å’Œæ¢å¤

é€šè¿‡è¿™äº›æ”¹è¿›ï¼Œæˆ‘ä»¬çš„é¡¹ç›®å°†è·å¾—æ›´å¥½çš„æ€§èƒ½ã€æ›´å¼ºçš„å…¼å®¹æ€§å’Œæ›´æ˜“çš„ç»´æŠ¤æ€§ã€‚

---

*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: 2025-01-27*  
*ç‰ˆæœ¬: v1.0*  
*åŸºäº: LangChain å®˜æ–¹æ–‡æ¡£å’Œæœ€ä½³å®è·µ*
