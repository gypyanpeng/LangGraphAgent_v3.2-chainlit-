# é¡¹ç›®ä¼˜åŒ–æ”¹è¿›å»ºè®®æŠ¥å‘Š

## ğŸ“‹ æŠ¥å‘Šæ¦‚è¿°

**ç”Ÿæˆæ—¶é—´**: 2025-06-28  
**é¡¹ç›®åç§°**: LangGraphAgentv3.2  
**å®¡æŸ¥èŒƒå›´**: LangGraph å®ç°ã€é”™è¯¯å¤„ç†ã€ä»£ç æ¶æ„  
**ç›®æ ‡**: æä¾›å…·ä½“çš„ä¼˜åŒ–å»ºè®®ï¼Œéµå¾ªå®˜æ–¹æœ€ä½³å®è·µ  

---

## ğŸ¯ ä¸»è¦æ”¹è¿›é¢†åŸŸ

### 1. é”™è¯¯å¤„ç†ä¼˜åŒ–

#### 1.1 å½“å‰é—®é¢˜åˆ†æ

**é—®é¢˜1: é”™è¯¯å¤„ç†è¿‡äºç®€å•**
```python
# å½“å‰å®ç° (main.py:211-215)
except Exception as e:
    print(f"âš ï¸ æ¨¡å‹è°ƒç”¨å‡ºé”™: {e}")
    from langchain_core.messages import AIMessage
    error_response = AIMessage(content=f"æŠ±æ­‰ï¼Œå¤„ç†è¯·æ±‚æ—¶å‡ºç°é”™è¯¯: {str(e)}")
    return {"messages": [error_response]}
```

**é—®é¢˜åˆ†æ**:
- æ•è·æ‰€æœ‰å¼‚å¸¸ç±»å‹ï¼Œç¼ºä¹ç»†åˆ†å¤„ç†
- é”™è¯¯ä¿¡æ¯ç›´æ¥æš´éœ²ç»™ç”¨æˆ·ï¼Œå¯èƒ½åŒ…å«æ•æ„Ÿä¿¡æ¯
- æ²¡æœ‰é”™è¯¯æ—¥å¿—è®°å½•å’Œç›‘æ§
- ç¼ºä¹é‡è¯•æœºåˆ¶

#### 1.2 æ”¹è¿›å»ºè®®

**å»ºè®®1: å®ç°åˆ†å±‚é”™è¯¯å¤„ç†**
```python
# æ¨èå®ç°
import logging
from typing import Optional
from langchain_core.exceptions import LangChainException
from langchain_core.messages import AIMessage

logger = logging.getLogger(__name__)

class AgentError(Exception):
    """Agent è‡ªå®šä¹‰å¼‚å¸¸åŸºç±»"""
    pass

class ModelCallError(AgentError):
    """æ¨¡å‹è°ƒç”¨å¼‚å¸¸"""
    pass

class ToolExecutionError(AgentError):
    """å·¥å…·æ‰§è¡Œå¼‚å¸¸"""
    pass

def call_model_with_error_handling(state: AgentState) -> dict:
    """å¸¦å®Œå–„é”™è¯¯å¤„ç†çš„æ¨¡å‹è°ƒç”¨"""
    messages = state["messages"]
    
    try:
        response = llm_with_tools.invoke(messages)
        
        # éªŒè¯å“åº”
        if not response.content and not (hasattr(response, 'tool_calls') and response.tool_calls):
            logger.warning("æ¨¡å‹è¿”å›ç©ºå“åº”")
            response = AIMessage(content="æŠ±æ­‰ï¼Œæˆ‘éœ€è¦æ›´å¤šä¿¡æ¯æ¥å¸®åŠ©æ‚¨ã€‚è¯·é‡æ–°æè¿°æ‚¨çš„é—®é¢˜ã€‚")
        
        return {"messages": [response]}
        
    except LangChainException as e:
        logger.error(f"LangChainå¼‚å¸¸: {e}", exc_info=True)
        error_response = AIMessage(content="æŠ±æ­‰ï¼Œè¯­è¨€æ¨¡å‹æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•ã€‚")
        return {"messages": [error_response]}
        
    except ConnectionError as e:
        logger.error(f"è¿æ¥é”™è¯¯: {e}", exc_info=True)
        error_response = AIMessage(content="æŠ±æ­‰ï¼Œç½‘ç»œè¿æ¥å‡ºç°é—®é¢˜ï¼Œè¯·æ£€æŸ¥ç½‘ç»œåé‡è¯•ã€‚")
        return {"messages": [error_response]}
        
    except TimeoutError as e:
        logger.error(f"è¶…æ—¶é”™è¯¯: {e}", exc_info=True)
        error_response = AIMessage(content="æŠ±æ­‰ï¼Œè¯·æ±‚å¤„ç†è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•ã€‚")
        return {"messages": [error_response]}
        
    except Exception as e:
        logger.error(f"æœªçŸ¥é”™è¯¯: {e}", exc_info=True)
        error_response = AIMessage(content="æŠ±æ­‰ï¼Œç³»ç»Ÿå‡ºç°äº†æœªçŸ¥é”™è¯¯ï¼Œè¯·è”ç³»ç®¡ç†å‘˜ã€‚")
        return {"messages": [error_response]}
```

**å»ºè®®2: æ·»åŠ é‡è¯•æœºåˆ¶**
```python
import asyncio
from functools import wraps

def retry_on_failure(max_retries: int = 3, delay: float = 1.0):
    """é‡è¯•è£…é¥°å™¨"""
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            last_exception = None
            
            for attempt in range(max_retries):
                try:
                    return await func(*args, **kwargs)
                except (ConnectionError, TimeoutError) as e:
                    last_exception = e
                    if attempt < max_retries - 1:
                        logger.warning(f"ç¬¬{attempt + 1}æ¬¡å°è¯•å¤±è´¥ï¼Œ{delay}ç§’åé‡è¯•: {e}")
                        await asyncio.sleep(delay * (2 ** attempt))  # æŒ‡æ•°é€€é¿
                    else:
                        logger.error(f"æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†: {e}")
                        raise
                except Exception as e:
                    # å¯¹äºå…¶ä»–å¼‚å¸¸ï¼Œä¸é‡è¯•
                    raise
            
            raise last_exception
        return wrapper
    return decorator
```

### 2. LangGraph æ¶æ„ä¼˜åŒ–

#### 2.1 å…³äº create_react_agent çš„ä½¿ç”¨

**é—®é¢˜**: æ˜¯å¦åº”è¯¥ä½¿ç”¨å®˜æ–¹çš„ `create_react_agent`ï¼Ÿ

**åˆ†æ**:
- `create_react_agent` æ˜¯ LangGraph æä¾›çš„é¢„æ„å»ºä»£ç†
- **ä¸ä»…é™äºå¤šæ™ºèƒ½ä½“åœºæ™¯**ï¼Œå•æ™ºèƒ½ä½“ä¹Ÿå¯ä»¥ä½¿ç”¨
- æä¾›äº†æ ‡å‡†åŒ–çš„ ReAct æ¨¡å¼å®ç°
- å‡å°‘äº†æ ·æ¿ä»£ç ï¼Œæé«˜äº†å¯ç»´æŠ¤æ€§

**å½“å‰å®ç° vs create_react_agent å¯¹æ¯”**:

```python
# å½“å‰å®ç° (æ‰‹åŠ¨æ„å»º)
workflow = StateGraph(AgentState)
workflow.add_node("agent", call_model)
workflow.add_node("tools", tool_node)
workflow.set_entry_point("agent")
workflow.add_conditional_edges("agent", should_continue, ["tools", END])
workflow.add_edge("tools", "agent")

# æ¨èä½¿ç”¨ create_react_agent
from langgraph.prebuilt import create_react_agent

app = create_react_agent(
    model=llm_with_tools,
    tools=tools,
    checkpointer=checkpointer,
    state_modifier="You are a helpful AI assistant."  # ç³»ç»Ÿæç¤º
)
```

**å»ºè®®**: 
- âœ… **æ¨èè¿ç§»åˆ° create_react_agent**
- ä¼˜åŠ¿: ä»£ç æ›´ç®€æ´ã€å®˜æ–¹ç»´æŠ¤ã€æœ€ä½³å®è·µå†…ç½®
- é€‚ç”¨åœºæ™¯: æ ‡å‡†çš„å·¥å…·è°ƒç”¨ä»£ç†ï¼ˆå½“å‰é¡¹ç›®å®Œå…¨é€‚ç”¨ï¼‰

#### 2.2 çŠ¶æ€ç®¡ç†ä¼˜åŒ–

**å½“å‰é—®é¢˜**:
```python
# è¿‡äºç®€å•çš„çŠ¶æ€å®šä¹‰
class AgentState(MessagesState):
    """ä½¿ç”¨å®˜æ–¹çš„ MessagesStateï¼ŒåŒ…å« messages å­—æ®µ"""
    pass
```

**æ”¹è¿›å»ºè®®**:
```python
from typing import Annotated, TypedDict
from langgraph.graph.message import add_messages

class EnhancedAgentState(TypedDict):
    """å¢å¼ºçš„ä»£ç†çŠ¶æ€"""
    messages: Annotated[list, add_messages]
    user_id: str
    session_metadata: dict
    error_count: int
    last_tool_used: Optional[str]
    conversation_summary: Optional[str]
```

### 3. é…ç½®ç®¡ç†ä¼˜åŒ–

#### 3.1 ç¯å¢ƒå˜é‡ç®¡ç†

**å½“å‰é—®é¢˜**: ç¡¬ç¼–ç çš„ç¯å¢ƒå˜é‡è®¾ç½®
```python
# å½“å‰å®ç° (main.py:14-20)
os.environ["LANGCHAIN_TRACING_V2"] = "false"
os.environ["LANGCHAIN_ENDPOINT"] = ""
# ...
```

**æ”¹è¿›å»ºè®®**: ä½¿ç”¨é…ç½®æ–‡ä»¶å’Œç¯å¢ƒå˜é‡ç®¡ç†
```python
# config/app_config.py
import os
from typing import Optional
from pydantic import BaseSettings

class AppConfig(BaseSettings):
    """åº”ç”¨é…ç½®"""
    # LangSmith é…ç½®
    langchain_tracing_v2: bool = False
    langchain_endpoint: str = ""
    langchain_api_key: str = ""
    langchain_project: str = ""
    
    # åº”ç”¨é…ç½®
    debug_mode: bool = False
    log_level: str = "INFO"
    max_retries: int = 3
    request_timeout: int = 60
    
    class Config:
        env_file = ".env"
        env_prefix = "APP_"

# ä½¿ç”¨é…ç½®
config = AppConfig()
```

### 4. æ—¥å¿—ç³»ç»Ÿä¼˜åŒ–

**å½“å‰é—®é¢˜**: ç¼ºä¹ç»Ÿä¸€çš„æ—¥å¿—ç³»ç»Ÿ

**æ”¹è¿›å»ºè®®**:
```python
# utils/logging_config.py
import logging
import sys
from pathlib import Path

def setup_logging(log_level: str = "INFO", log_file: Optional[str] = None):
    """è®¾ç½®ç»Ÿä¸€çš„æ—¥å¿—ç³»ç»Ÿ"""
    
    # åˆ›å»ºæ—¥å¿—æ ¼å¼
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(filename)s:%(lineno)d - %(message)s'
    )
    
    # æ§åˆ¶å°å¤„ç†å™¨
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setFormatter(formatter)
    
    # æ–‡ä»¶å¤„ç†å™¨
    handlers = [console_handler]
    if log_file:
        file_handler = logging.FileHandler(log_file)
        file_handler.setFormatter(formatter)
        handlers.append(file_handler)
    
    # é…ç½®æ ¹æ—¥å¿—å™¨
    logging.basicConfig(
        level=getattr(logging, log_level.upper()),
        handlers=handlers
    )
    
    # è®¾ç½®ç¬¬ä¸‰æ–¹åº“æ—¥å¿—çº§åˆ«
    logging.getLogger("httpx").setLevel(logging.WARNING)
    logging.getLogger("httpcore").setLevel(logging.WARNING)
```

### 5. æ€§èƒ½ä¼˜åŒ–å»ºè®®

#### 5.1 è¿æ¥æ± ç®¡ç†
```python
# ollama_adapter.py ä¼˜åŒ–
import aiohttp
from typing import Optional

class OllamaChatModel(BaseChatModel):
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self._session: Optional[aiohttp.ClientSession] = None
    
    async def get_session(self) -> aiohttp.ClientSession:
        """è·å–æˆ–åˆ›å»ºä¼šè¯"""
        if self._session is None or self._session.closed:
            connector = aiohttp.TCPConnector(
                limit=100,  # è¿æ¥æ± å¤§å°
                limit_per_host=30,
                keepalive_timeout=30
            )
            self._session = aiohttp.ClientSession(
                connector=connector,
                timeout=aiohttp.ClientTimeout(total=60)
            )
        return self._session
    
    async def close(self):
        """å…³é—­ä¼šè¯"""
        if self._session and not self._session.closed:
            await self._session.close()
```

#### 5.2 ç¼“å­˜æœºåˆ¶
```python
# utils/cache.py
from functools import lru_cache
import hashlib
import json

class ResponseCache:
    """å“åº”ç¼“å­˜"""
    
    def __init__(self, max_size: int = 1000):
        self.cache = {}
        self.max_size = max_size
    
    def get_cache_key(self, messages: list, model: str) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        content = json.dumps([msg.content for msg in messages], sort_keys=True)
        return hashlib.md5(f"{model}:{content}".encode()).hexdigest()
    
    def get(self, key: str):
        """è·å–ç¼“å­˜"""
        return self.cache.get(key)
    
    def set(self, key: str, value):
        """è®¾ç½®ç¼“å­˜"""
        if len(self.cache) >= self.max_size:
            # ç®€å•çš„ LRU å®ç°
            oldest_key = next(iter(self.cache))
            del self.cache[oldest_key]
        self.cache[key] = value
```

---

## ğŸš€ å®æ–½ä¼˜å…ˆçº§

### é«˜ä¼˜å…ˆçº§ (ç«‹å³å®æ–½)
1. **é”™è¯¯å¤„ç†ä¼˜åŒ–** - æå‡ç”¨æˆ·ä½“éªŒå’Œç³»ç»Ÿç¨³å®šæ€§
2. **æ—¥å¿—ç³»ç»Ÿå®Œå–„** - ä¾¿äºé—®é¢˜æ’æŸ¥å’Œç›‘æ§
3. **é…ç½®ç®¡ç†ä¼˜åŒ–** - æé«˜éƒ¨ç½²çµæ´»æ€§

### ä¸­ä¼˜å…ˆçº§ (è¿‘æœŸå®æ–½)
1. **è¿ç§»åˆ° create_react_agent** - ç®€åŒ–ä»£ç ï¼Œéµå¾ªæœ€ä½³å®è·µ
2. **çŠ¶æ€ç®¡ç†å¢å¼º** - æ”¯æŒæ›´å¤æ‚çš„ä¸šåŠ¡é€»è¾‘
3. **è¿æ¥æ± ä¼˜åŒ–** - æå‡æ€§èƒ½

### ä½ä¼˜å…ˆçº§ (é•¿æœŸè§„åˆ’)
1. **ç¼“å­˜æœºåˆ¶** - ä¼˜åŒ–å“åº”é€Ÿåº¦
2. **ç›‘æ§å’ŒæŒ‡æ ‡** - ç”Ÿäº§ç¯å¢ƒç›‘æ§
3. **æµ‹è¯•è¦†ç›–ç‡æå‡** - ç¡®ä¿ä»£ç è´¨é‡

---

## ğŸ”§ å…·ä½“å®æ–½æŒ‡å—

### é˜¶æ®µä¸€: é”™è¯¯å¤„ç†ä¼˜åŒ– (1-2å¤©)

**æ­¥éª¤1: åˆ›å»ºé”™è¯¯å¤„ç†æ¨¡å—**
```bash
mkdir utils
touch utils/__init__.py
touch utils/error_handling.py
touch utils/logging_config.py
```

**æ­¥éª¤2: å®æ–½åˆ†å±‚é”™è¯¯å¤„ç†**
- æ›¿æ¢ `main.py` ä¸­çš„ `call_model` å‡½æ•°
- æ·»åŠ é‡è¯•æœºåˆ¶åˆ° `ollama_adapter.py`
- æ›´æ–° `chainlit_app.py` çš„é”™è¯¯å¤„ç†

**æ­¥éª¤3: æµ‹è¯•éªŒè¯**
- æ¨¡æ‹Ÿç½‘ç»œé”™è¯¯æµ‹è¯•é‡è¯•æœºåˆ¶
- éªŒè¯é”™è¯¯æ¶ˆæ¯çš„ç”¨æˆ·å‹å¥½æ€§
- æ£€æŸ¥æ—¥å¿—è®°å½•çš„å®Œæ•´æ€§

### é˜¶æ®µäºŒ: è¿ç§»åˆ° create_react_agent (2-3å¤©)

**æ­¥éª¤1: å¤‡ä»½å½“å‰å®ç°**
```bash
cp main.py main_backup.py
```

**æ­¥éª¤2: é‡æ„ Agent åˆ›å»ºé€»è¾‘**
```python
# æ–°çš„ main.py å®ç°ç¤ºä¾‹
from langgraph.prebuilt import create_react_agent

async def initialize_agent_v2():
    """ä½¿ç”¨ create_react_agent çš„æ–°å®ç°"""
    # åŠ è½½é…ç½®
    persistence_config = load_persistence_config("config/persistence_config.json")
    checkpointer = await create_checkpointer(persistence_config)
    session_manager = SimpleSessionManager(persistence_config)

    # åŠ è½½æ¨¡å‹å’Œå·¥å…·
    llm = load_llm_from_config("config/llm_config.json")
    _, tools = await load_mcp_tools_from_config("config/mcp_config.json")

    # ä½¿ç”¨å®˜æ–¹é¢„æ„å»ºä»£ç†
    app = create_react_agent(
        model=llm,
        tools=tools,
        checkpointer=checkpointer,
        state_modifier="ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ï¼Œå¯ä»¥ä½¿ç”¨å„ç§å·¥å…·æ¥å¸®åŠ©ç”¨æˆ·è§£å†³é—®é¢˜ã€‚"
    )

    return app, tools, session_manager
```

**æ­¥éª¤3: æ¸è¿›å¼è¿ç§»**
- å…ˆåœ¨æµ‹è¯•ç¯å¢ƒéªŒè¯æ–°å®ç°
- å¯¹æ¯”æ–°æ—§å®ç°çš„åŠŸèƒ½ä¸€è‡´æ€§
- ç¡®ä¿ Chainlit é›†æˆæ­£å¸¸å·¥ä½œ

### é˜¶æ®µä¸‰: é…ç½®å’Œæ—¥å¿—ä¼˜åŒ– (1å¤©)

**æ­¥éª¤1: ç¯å¢ƒé…ç½®æ ‡å‡†åŒ–**
- åˆ›å»º `.env.example` æ–‡ä»¶
- å®æ–½ `AppConfig` ç±»
- æ›´æ–°æ‰€æœ‰ç¡¬ç¼–ç é…ç½®

**æ­¥éª¤2: æ—¥å¿—ç³»ç»Ÿå®Œå–„**
- ç»Ÿä¸€æ—¥å¿—æ ¼å¼
- æ·»åŠ æ—¥å¿—è½®è½¬
- é›†æˆæ€§èƒ½ç›‘æ§

## ğŸ§ª æµ‹è¯•ç­–ç•¥

### å•å…ƒæµ‹è¯•å¢å¼º
```python
# tests/test_error_handling.py
import pytest
from unittest.mock import patch, AsyncMock
from utils.error_handling import call_model_with_error_handling

@pytest.mark.asyncio
async def test_model_call_with_connection_error():
    """æµ‹è¯•è¿æ¥é”™è¯¯çš„å¤„ç†"""
    with patch('llm_with_tools.invoke', side_effect=ConnectionError("ç½‘ç»œé”™è¯¯")):
        result = await call_model_with_error_handling(mock_state)
        assert "ç½‘ç»œè¿æ¥å‡ºç°é—®é¢˜" in result["messages"][0].content

@pytest.mark.asyncio
async def test_retry_mechanism():
    """æµ‹è¯•é‡è¯•æœºåˆ¶"""
    with patch('llm_with_tools.invoke', side_effect=[
        ConnectionError("ç¬¬ä¸€æ¬¡å¤±è´¥"),
        ConnectionError("ç¬¬äºŒæ¬¡å¤±è´¥"),
        AIMessage(content="æˆåŠŸå“åº”")
    ]):
        result = await call_model_with_error_handling(mock_state)
        assert result["messages"][0].content == "æˆåŠŸå“åº”"
```

### é›†æˆæµ‹è¯•
```python
# tests/test_agent_integration.py
@pytest.mark.asyncio
async def test_create_react_agent_integration():
    """æµ‹è¯•æ–°çš„ create_react_agent é›†æˆ"""
    app, tools, session_manager = await initialize_agent_v2()

    # æµ‹è¯•åŸºæœ¬å¯¹è¯
    config = {"configurable": {"thread_id": "test_thread"}}
    result = await app.ainvoke(
        {"messages": [HumanMessage(content="ä½ å¥½")]},
        config=config
    )

    assert len(result["messages"]) > 1
    assert isinstance(result["messages"][-1], AIMessage)
```

## ğŸ“Š æ€§èƒ½åŸºå‡†æµ‹è¯•

### å½“å‰æ€§èƒ½åŸºçº¿
```python
# tests/performance_benchmark.py
import time
import asyncio
from statistics import mean, stdev

async def benchmark_agent_response_time():
    """åŸºå‡†æµ‹è¯•ä»£ç†å“åº”æ—¶é—´"""
    response_times = []

    for i in range(10):
        start_time = time.time()
        await app.ainvoke({"messages": [HumanMessage(content=f"æµ‹è¯•æ¶ˆæ¯ {i}")]})
        end_time = time.time()
        response_times.append(end_time - start_time)

    print(f"å¹³å‡å“åº”æ—¶é—´: {mean(response_times):.2f}s")
    print(f"å“åº”æ—¶é—´æ ‡å‡†å·®: {stdev(response_times):.2f}s")
    print(f"æœ€å¿«å“åº”: {min(response_times):.2f}s")
    print(f"æœ€æ…¢å“åº”: {max(response_times):.2f}s")
```

## ğŸ” ä»£ç è´¨é‡æ£€æŸ¥

### é™æ€ä»£ç åˆ†æ
```bash
# å®‰è£…ä»£ç è´¨é‡å·¥å…·
pip install black isort flake8 mypy

# ä»£ç æ ¼å¼åŒ–
black .
isort .

# ä»£ç æ£€æŸ¥
flake8 --max-line-length=100 --ignore=E203,W503 .
mypy --ignore-missing-imports .
```

### å®‰å…¨æ€§æ£€æŸ¥
```bash
# å®‰å…¨æ¼æ´æ‰«æ
pip install bandit safety

# æ£€æŸ¥ä»£ç å®‰å…¨é—®é¢˜
bandit -r .

# æ£€æŸ¥ä¾èµ–å®‰å…¨é—®é¢˜
safety check
```

## ğŸ“ˆ ç›‘æ§å’ŒæŒ‡æ ‡

### åº”ç”¨æŒ‡æ ‡æ”¶é›†
```python
# utils/metrics.py
import time
from functools import wraps
from typing import Dict, Any
import logging

class MetricsCollector:
    """æŒ‡æ ‡æ”¶é›†å™¨"""

    def __init__(self):
        self.metrics = {
            "request_count": 0,
            "error_count": 0,
            "response_times": [],
            "tool_usage": {}
        }

    def record_request(self, response_time: float, success: bool = True):
        """è®°å½•è¯·æ±‚æŒ‡æ ‡"""
        self.metrics["request_count"] += 1
        self.metrics["response_times"].append(response_time)

        if not success:
            self.metrics["error_count"] += 1

    def record_tool_usage(self, tool_name: str):
        """è®°å½•å·¥å…·ä½¿ç”¨"""
        if tool_name not in self.metrics["tool_usage"]:
            self.metrics["tool_usage"][tool_name] = 0
        self.metrics["tool_usage"][tool_name] += 1

    def get_summary(self) -> Dict[str, Any]:
        """è·å–æŒ‡æ ‡æ‘˜è¦"""
        if not self.metrics["response_times"]:
            return self.metrics

        response_times = self.metrics["response_times"]
        return {
            **self.metrics,
            "avg_response_time": sum(response_times) / len(response_times),
            "error_rate": self.metrics["error_count"] / self.metrics["request_count"]
        }

# å…¨å±€æŒ‡æ ‡æ”¶é›†å™¨
metrics = MetricsCollector()
```

---

## ğŸ“ æ€»ç»“

å½“å‰é¡¹ç›®æ•´ä½“æ¶æ„è‰¯å¥½ï¼Œä¸»è¦éœ€è¦åœ¨é”™è¯¯å¤„ç†ã€æ—¥å¿—è®°å½•å’Œé…ç½®ç®¡ç†æ–¹é¢è¿›è¡Œä¼˜åŒ–ã€‚å»ºè®®ä¼˜å…ˆå®æ–½é«˜ä¼˜å…ˆçº§çš„æ”¹è¿›é¡¹ï¼Œè¿™äº›æ”¹è¿›å°†æ˜¾è‘—æå‡ç³»ç»Ÿçš„ç¨³å®šæ€§å’Œå¯ç»´æŠ¤æ€§ã€‚

å…³äº `create_react_agent` çš„ä½¿ç”¨ï¼Œå¼ºçƒˆå»ºè®®è¿ç§»ï¼Œè¿™ä¸ä»…é€‚ç”¨äºå¤šæ™ºèƒ½ä½“åœºæ™¯ï¼Œå¯¹å•æ™ºèƒ½ä½“ä¹Ÿèƒ½å¸¦æ¥ä»£ç ç®€åŒ–å’Œæœ€ä½³å®è·µçš„å¥½å¤„ã€‚

### é¢„æœŸæ”¶ç›Š
- **ç¨³å®šæ€§æå‡**: é”™è¯¯å¤„ç†ä¼˜åŒ–å°†å‡å°‘ 80% çš„ç”¨æˆ·å¯è§é”™è¯¯
- **ç»´æŠ¤æ•ˆç‡**: ç»Ÿä¸€æ—¥å¿—ç³»ç»Ÿå°†æé«˜é—®é¢˜æ’æŸ¥æ•ˆç‡ 50%
- **ä»£ç è´¨é‡**: è¿ç§»åˆ°å®˜æ–¹é¢„æ„å»ºä»£ç†å°†å‡å°‘ 30% çš„ä»£ç é‡
- **æ€§èƒ½ä¼˜åŒ–**: è¿æ¥æ± å’Œç¼“å­˜æœºåˆ¶å°†æå‡ 20% çš„å“åº”é€Ÿåº¦

### é£é™©æ§åˆ¶
- æ¸è¿›å¼å®æ–½ï¼Œæ¯ä¸ªé˜¶æ®µéƒ½æœ‰å›æ»šæ–¹æ¡ˆ
- å®Œæ•´çš„æµ‹è¯•è¦†ç›–ï¼Œç¡®ä¿åŠŸèƒ½ä¸å›é€€
- æ€§èƒ½åŸºå‡†æµ‹è¯•ï¼Œç¡®ä¿ä¼˜åŒ–æ•ˆæœ
- è¯¦ç»†çš„æ–‡æ¡£è®°å½•ï¼Œä¾¿äºå›¢é˜Ÿåä½œ
