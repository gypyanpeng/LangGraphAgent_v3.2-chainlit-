#!/usr/bin/env python3
"""
æ•°æ®åº“æ¸…ç†è„šæœ¬
å®‰å…¨åˆ é™¤ä¸éœ€è¦çš„æ•°æ®åº“æ–‡ä»¶
"""

import os
import sys
import sqlite3
from pathlib import Path

def check_database_usage(db_path):
    """æ£€æŸ¥æ•°æ®åº“æ˜¯å¦è¢«ä½¿ç”¨ï¼ˆæ˜¯å¦æœ‰æ•°æ®ï¼‰"""
    try:
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        # è·å–æ‰€æœ‰è¡¨
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
        tables = cursor.fetchall()
        
        if not tables:
            conn.close()
            return False, "æ•°æ®åº“ä¸ºç©ºï¼ˆæ— è¡¨ï¼‰"
        
        # æ£€æŸ¥æ¯ä¸ªè¡¨æ˜¯å¦æœ‰æ•°æ®
        total_rows = 0
        table_info = []
        
        for table in tables:
            table_name = table[0]
            cursor.execute(f"SELECT COUNT(*) FROM {table_name};")
            count = cursor.fetchone()[0]
            total_rows += count
            table_info.append(f"{table_name}: {count} è¡Œ")
        
        conn.close()
        
        if total_rows == 0:
            return False, f"æ•°æ®åº“ä¸ºç©ºï¼ˆ{len(tables)} ä¸ªè¡¨ï¼Œ0 è¡Œæ•°æ®ï¼‰"
        else:
            return True, f"æ•°æ®åº“æœ‰æ•°æ®ï¼ˆ{len(tables)} ä¸ªè¡¨ï¼Œ{total_rows} è¡Œæ•°æ®ï¼‰\n  " + "\n  ".join(table_info)
            
    except Exception as e:
        return None, f"æ£€æŸ¥å¤±è´¥: {str(e)}"

def analyze_databases():
    """åˆ†ææ‰€æœ‰æ•°æ®åº“æ–‡ä»¶"""
    data_dir = Path("data")
    
    if not data_dir.exists():
        print("âŒ data ç›®å½•ä¸å­˜åœ¨")
        return
    
    print("ğŸ” åˆ†ææ•°æ®åº“æ–‡ä»¶...")
    print("=" * 60)
    
    db_files = list(data_dir.glob("*.db"))
    
    if not db_files:
        print("ğŸ“ data ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°æ•°æ®åº“æ–‡ä»¶")
        return
    
    analysis_results = {}
    
    for db_file in sorted(db_files):
        print(f"\nğŸ“Š åˆ†æ: {db_file.name}")
        print("-" * 40)
        
        file_size = db_file.stat().st_size
        print(f"æ–‡ä»¶å¤§å°: {file_size:,} å­—èŠ‚ ({file_size/1024:.1f} KB)")
        
        has_data, info = check_database_usage(str(db_file))
        
        if has_data is None:
            print(f"âš ï¸  {info}")
            analysis_results[db_file.name] = "error"
        elif has_data:
            print(f"âœ… {info}")
            analysis_results[db_file.name] = "used"
        else:
            print(f"ğŸ—‘ï¸  {info}")
            analysis_results[db_file.name] = "empty"
    
    return analysis_results

def cleanup_empty_databases(analysis_results, dry_run=True):
    """æ¸…ç†ç©ºæ•°æ®åº“æ–‡ä»¶"""
    data_dir = Path("data")
    
    empty_files = [name for name, status in analysis_results.items() if status == "empty"]
    
    if not empty_files:
        print("\nâœ… æ²¡æœ‰å‘ç°éœ€è¦æ¸…ç†çš„ç©ºæ•°æ®åº“æ–‡ä»¶")
        return
    
    print(f"\nğŸ—‘ï¸  å‘ç° {len(empty_files)} ä¸ªç©ºæ•°æ®åº“æ–‡ä»¶:")
    for file_name in empty_files:
        print(f"  - {file_name}")
    
    if dry_run:
        print("\nğŸ” è¿™æ˜¯é¢„è§ˆæ¨¡å¼ï¼Œä¸ä¼šå®é™…åˆ é™¤æ–‡ä»¶")
        print("å¦‚è¦å®é™…åˆ é™¤ï¼Œè¯·è¿è¡Œ: python scripts/cleanup_databases.py --execute")
        return
    
    # å®é™…åˆ é™¤
    print(f"\nâš ï¸  å‡†å¤‡åˆ é™¤ {len(empty_files)} ä¸ªæ–‡ä»¶...")
    
    for file_name in empty_files:
        file_path = data_dir / file_name
        try:
            # åˆ›å»ºå¤‡ä»½
            backup_path = data_dir / f"{file_name}.backup"
            file_path.rename(backup_path)
            print(f"âœ… å·²å¤‡ä»½å¹¶åˆ é™¤: {file_name} -> {file_name}.backup")
        except Exception as e:
            print(f"âŒ åˆ é™¤å¤±è´¥ {file_name}: {str(e)}")

def show_recommendations():
    """æ˜¾ç¤ºä¼˜åŒ–å»ºè®®"""
    print("\n" + "=" * 60)
    print("ğŸ“‹ æ•°æ®åº“ä¼˜åŒ–å»ºè®®")
    print("=" * 60)
    
    recommendations = [
        "ğŸ”„ å®šæœŸå¤‡ä»½é‡è¦æ•°æ®åº“æ–‡ä»¶:",
        "  - agent_memory.db (LangGraph çŠ¶æ€æ•°æ®)",
        "  - chainlit_history.db (ç”¨æˆ·ç•Œé¢æ•°æ®)",
        "  - agent_data.db (ä¸šåŠ¡æ•°æ®)",
        "",
        "ğŸ—‘ï¸  å¯ä»¥å®‰å…¨åˆ é™¤çš„æ–‡ä»¶:",
        "  - chainlit.db (å¦‚æœä¸ºç©º)",
        "  - *.db-journal (ä¸´æ—¶æ–‡ä»¶)",
        "",
        "âš¡ æ€§èƒ½ä¼˜åŒ–æ–‡ä»¶ï¼ˆä¿ç•™ï¼‰:",
        "  - *.db-shm (å…±äº«å†…å­˜æ–‡ä»¶)",
        "  - *.db-wal (é¢„å†™æ—¥å¿—æ–‡ä»¶)",
        "",
        "ğŸ“Š ç›‘æ§å»ºè®®:",
        "  - å®šæœŸæ£€æŸ¥æ•°æ®åº“å¤§å°",
        "  - ç›‘æ§æŸ¥è¯¢æ€§èƒ½",
        "  - è®¾ç½®è‡ªåŠ¨å¤‡ä»½è®¡åˆ’"
    ]
    
    for rec in recommendations:
        print(rec)

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§¹ LangGraph Agent æ•°æ®åº“æ¸…ç†å·¥å…·")
    print("=" * 60)
    
    # æ£€æŸ¥æ˜¯å¦åœ¨æ­£ç¡®çš„ç›®å½•
    if not Path("chainlit_app.py").exists():
        print("âŒ è¯·åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œæ­¤è„šæœ¬")
        sys.exit(1)
    
    # åˆ†ææ•°æ®åº“
    analysis_results = analyze_databases()
    
    if not analysis_results:
        return
    
    # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
    execute_cleanup = "--execute" in sys.argv
    
    # æ¸…ç†ç©ºæ•°æ®åº“
    cleanup_empty_databases(analysis_results, dry_run=not execute_cleanup)
    
    # æ˜¾ç¤ºå»ºè®®
    show_recommendations()
    
    print(f"\nğŸ‰ åˆ†æå®Œæˆï¼")

if __name__ == "__main__":
    main()
