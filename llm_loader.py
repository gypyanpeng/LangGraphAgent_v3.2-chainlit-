# llm_loader.py
import json
import os
from typing import Optional
from langchain_openai import ChatOpenAI

def load_llm_from_config(config_path: str = "config/llm_config.json", provider: Optional[str] = None):
    """
    åªç”¨ openai/å®˜æ–¹ provider ç›´è¿ LLMï¼Œä¸ä½¿ç”¨ litellm proxyã€‚
    æ”¯æŒå¤šæ¨¡å‹é…ç½®ï¼Œprovider å¯é€‰ï¼Œé»˜è®¤åŠ è½½ default_providerã€‚
    é»˜è®¤é…ç½®æ–‡ä»¶è·¯å¾„ä¸º config/llm_config.jsonã€‚
    """
    with open(config_path, "r", encoding="utf-8") as f:
        config = json.load(f)
    # å…¼å®¹å•æ¨¡å‹å’Œå¤šæ¨¡å‹é…ç½®
    if "models" in config:
        models = config["models"]
        default_provider = config.get("default_provider")
        provider = provider or default_provider
        if provider not in models:
            raise ValueError(f"æœªæ‰¾åˆ° provider: {provider} çš„æ¨¡å‹é…ç½®")
        llm_conf = models[provider]
        model = llm_conf.get("model_name")
        api_key = llm_conf.get("api_key")
        api_base = llm_conf.get("base_url")
        temperature = llm_conf.get("temperature", 0.7)
        streaming = llm_conf.get("streaming", True)
    else:
        llm_conf = config["llm"]
        model = llm_conf.get("model")
        api_key = llm_conf.get("api_key")
        api_base = llm_conf.get("api_base")
        temperature = llm_conf.get("temperature", 0.7)
        streaming = llm_conf.get("streaming", True)
    return ChatOpenAI(
        model=model,
        api_key=api_key,
        base_url=api_base,
        temperature=temperature,
        streaming=streaming
    )

def list_available_models(config_path: str = "llm_config.json"):
    """
    åˆ—å‡ºé…ç½®æ–‡ä»¶ä¸­æ‰€æœ‰å¯ç”¨çš„æ¨¡å‹ã€‚

    Args:
        config_path (str): LLMé…ç½®æ–‡ä»¶çš„è·¯å¾„ã€‚

    Returns:
        dict: åŒ…å«æ‰€æœ‰æ¨¡å‹é…ç½®çš„å­—å…¸ã€‚
    """
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
    except FileNotFoundError:
        print(f"é”™è¯¯: é…ç½®æ–‡ä»¶ '{config_path}' æœªæ‰¾åˆ°ã€‚")
        return {}
    except json.JSONDecodeError:
        print(f"é”™è¯¯: æ— æ³•è§£æé…ç½®æ–‡ä»¶ '{config_path}'ã€‚")
        return {}

    if "models" not in config:
        print("âš ï¸ é…ç½®æ–‡ä»¶ä½¿ç”¨æ—§æ ¼å¼ï¼Œä¸æ”¯æŒå¤šæ¨¡å‹åˆ—è¡¨")
        return {}

    models = config.get("models", {})
    default_provider = config.get("default_provider")

    print("ğŸ“‹ å¯ç”¨æ¨¡å‹åˆ—è¡¨:")
    for provider, model_config in models.items():
        default_mark = " (é»˜è®¤)" if provider == default_provider else ""
        description = model_config.get("description", "")

        print(f"  - {provider}{default_mark}")
        print(f"    æ¨¡å‹: {model_config.get('model_name', 'N/A')}")
        print(f"    æè¿°: {description}")
        print(f"    URL: {model_config.get('base_url', 'N/A')}")
        print()

    return models